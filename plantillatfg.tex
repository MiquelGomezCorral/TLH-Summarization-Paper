%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                       CARGA DE LA CLASE DE DOCUMENTO                        %
%                                                                             %
% Las opciones admisibles son:                                                %
%      12pt / 11pt            (tamaño del cuerpo de letra; no usar 10pt)      %
%                                                                             %
% catalan/spanish/english     (idioma principal del trabajo)                  %
%                                                                             % 
% french/italian/german...    (si necesitáis usar otro idioma adicional)      %
%                                                                             %
% listoffigures               (El documento incluye un Índice de figuras)     %
% listoftables                (El documento incluye un Índice de tablas)      %
% listofquadres               (El documento incluye un Índice de cuadros)     %
% listofalgorithms            (El documento incluye un Índice de algoritmos)  %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt,spanish,listoffigures,listoftables]{tfgetsinf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                     CODIFICACIÓN DEL ARCHIVO FUENTE                         %
%                                                                             %
%    Windows suele usar 'ansinew'                                             %
%    en Linux es posible que sea 'latin1' o 'latin9'                          %
%    Pero lo más recomendable es usar utf8 (unicode 8)                        %
%                                          (si vuestro editor lo permite)     % 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[utf8]{inputenc} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                       OTROS PAQUETES Y DEFINICIONES                         %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{glossaries}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{float}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

% Listings para código
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily\small,
  frame=single,
  breaklines=true,
  postbreak=\mbox{\textcolor{gray}{$\hookrightarrow$}\space},
  columns=fullflexible,
  keepspaces=true,
  numbers=none
}

% Bibliografía
\usepackage[backend=biber,style=numeric,sorting=none]{biblatex}
\addbibresource{bibliografia.bib}

% Hyperref siempre al final
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=black,
  urlcolor=cyan,
  citecolor=black
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                          DATOS DEL TRABAJO                                  %
%                                                                             %
% título alumno, titor y curso académico                                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Resúmenes Automáticos Extractivos y Abstractivos}
\author{André Pachedo, \\ Miquel Gómez}
% \tutor{No}
% \curs{MUIARFID}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                     PARAULES CLAU/PALABRAS CLAVE/KEY WORDS                  %
%                                                                             %
% Independentment de la llengua del treball, s'hi han d'incloure              %
% les paraules clau i el resum en els tres idiomes                            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\keywords{
    Traducción de textos; español; esperanto; Transformers; LLMs
} % Paraules clau 
{
   Traducción de textos; 
} % Palabras clave
{
    Text clasification.
} % Key words


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
%                              INICI DEL DOCUMENT                             %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%              RESUMENES DEL TFG EN VALENCIA, CASTELLA I ANGLES               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \begin{abstract}[spanish]

% \end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
%                              CONTENIDO DEL TREBAJO                          %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                  ÍDNICE                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \clearpage
% \tableofcontents
% \listoffigures
% \listoftables


\mainmatter

\chapter{Análisis de los Resultados}

Los métodos generativos nos han ayudado a entender ...
\section{Análisis de Rendimiento}
% **TAREA:** Realiza un análisis **para cada una de las tablas** de resultados que incluya, como mínimo, la contestación a las siguientes preguntas. Se espera un análisis redactado (como en un artículo científico), no un *itemize*.

% 1. ¿Qué nos dicen los resultados de los Oráculos Extractivos?
% 2. ¿Qué nos indican los resultados del método *naive* LEAD-3?
% 3. ¿Crees que con un mejor método extractivo podríamos llegar a obtener una mejora notable?
% 4. ¿Qué rendimiento tienen los métodos Extractivos (excluyendo LEAD-3) en los 4 aspectos?
% 5. ¿Qué rendimiento tienen los modelos Sequence2Sequence en los 4 aspectos?
% 6. ¿Qué rendimiento tienen los modelos Causales en los 4 aspectos?
% 7. Comparando todos los tipos de métodos (sin incluir LEAD-3) ¿Qué método extractivo y qué modelo abstractivo son los más balanceados?

Primero que todo, a partir de las tablas de resultados, los oráculos extractivos nos marcan el límite superior del rendimiento que podríamos esperar de cualquier método extractivo. Cuanto valoremos los resultados de los NO oráculos, tomaremos estos valores como referencia para entender el margen de mejora que podríamos tener.

Por otro lado, el método Naive LEAD-3, nos sirve como una línea base simple para comparar los demás métodos y entender el dataset. Este nos dice cuenta información sobre los documentos se encuentra el las 3 primeras oraciones.

En un principio, bajo estar definiciones y teniendo en cuenta que todas las métricas parten de una referencia, un método extractivo NO podría superar el rendimiento de los oráculos extractivos. Los métodos podrían acercarse mucho a estos oráculos, pero no superarlos. 

\subsection{Dataset CNN/DailyMail}

\begin{table}[H]
\footnotesize
  \centering
\caption{Resultados de métricas automáticas para modelos extractivos y abstractivos (Tabla 1)}
\label{tab:resultados_nlp_1}
\begin{tabular}{lcccccccc}
\toprule
\textbf{Method} & \textbf{R-1} & \textbf{R-2} & \textbf{R-3} & \textbf{R-4} & \textbf{BS-r} & \textbf{BS-f} & \textbf{METEOR} & \textbf{CHRF} \\
\midrule
extractive-oracle-num-sents & \textbf{0.4617} & \textbf{0.2840} & \textbf{0.2155} & \textbf{0.1711} & \textbf{0.8792} & \textbf{0.8847} & \textbf{0.4165} & \textbf{47.7765} \\
extractive-oracle-ratio     & \textbf{0.4646} & \textbf{0.2829} & \textbf{0.2126} & \textbf{0.1666} & \textbf{0.8834} & \textbf{0.8860} & \textbf{0.4371} & \textbf{50.7997} \\
lead-3                      & 0.3788 & 0.1629 & 0.0931 & 0.0633 & 0.8695 & 0.8666 & 0.3683 & 42.8866 \\
tex-trank                   & 0.3459 & 0.1526 & 0.0905 & 0.0637 & 0.8726 & 0.8625 & 0.3561 & 41.9320 \\
lex-trank                   & 0.3473 & 0.1386 & 0.0764 & 0.0514 & 0.8672 & 0.8635 & 0.3301 & 39.4642 \\
lsa                         & 0.3123 & 0.1196 & 0.0690 & 0.0470 & 0.8641 & 0.8540 & 0.3274 & 39.1290 \\
bert-extractive             & 0.3321 & 0.1212 & 0.0649 & 0.0440 & 0.8637 & 0.8596 & 0.3184 & 38.7921 \\
bart                        & \textbf{0.4298} & 0.2031 & 0.1231 & 0.0848 & 0.8778 & \textbf{0.8804} & \textbf{0.3880} & \textbf{44.1239} \\
pegasus                     & 0.4209 & \textbf{0.2115} & \textbf{0.1297} & \textbf{0.0896} & \textbf{0.8827} & 0.8780 & 0.3580 & 41.6167 \\
flan-t5                     & 0.3567 & 0.1481 & 0.0796 & 0.0490 & 0.8580 & 0.8689 & 0.2811 & 34.4151 \\
gpt2                        & 0.1970 & 0.0322 & 0.0059 & 0.0017 & 0.8106 & 0.8149 & 0.1759 & 26.7276 \\
llama3                      & 0.2287 & 0.0475 & 0.0135 & 0.0046 & 0.8384 & 0.8413 & 0.2150 & 30.0470 \\
\bottomrule
\end{tabular}
\end{table}

\dots

Los Métodos extractivos parecen ser métodos estables y robustos. Tiende a obtener buenos resultados en todos los aspectos, aunque no son los mejores en ninguno. Sobre todo, flaquean un poco en la fluidez. Algo normal en métodos extractivos porque solo juntan frases.

Por otro lado, en los modelos Sequence2Sequence podemos agrupar en Bart y Pegasus por un lado, y el Flan-t5 por otro. Bart y Pegasus parecen tener el mejor rendimiento en todas las métricas. Sin embargo, Flan-t5 parece tener un rendimiento en comparación inferior.... .

Esto algo esperado ya que Bart y Pegasus han sido finetuneados específicamente para la tarea de resumen automático EN ESTE DATASE, mientras que Flan-t5 es un modelo más generalista.

Los modelos causales (GPT2 y Llama3) parecen tener un rendimiento bastante inferior a los demás métodos. Esto puede ser debido a que estos modelos no están tan especializados en la tarea de resumen automático como los otros modelos abstractivos. 


Viendo, podemos decir que el método extractivo más balanceado es TextRank, ya que obtiene resultados decentes en todos los aspectos sin destacar especialmente en ninguno. 

Por otro lado, Bart diríamos que en el modelo abstractivo más balanceado. Está empatado con Pegasus en dos métricas, pero en las que Pegasus le supera, no lo hace por mucho.

\subsection{Dataset CLASum}
\begin{table}[ht]
  \footnotesize
\centering
\caption{Resultados de métricas automáticas para modelos extractivos y abstractivos (Tabla 2)}
\label{tab:resultados_nlp_2}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\textbf{Method} & \textbf{R-1} & \textbf{R-2} & \textbf{R-3} & \textbf{R-4} & \textbf{BS-r} & \textbf{BS-f} & \textbf{METEOR} & \textbf{CHRF} \\
\midrule
extractive-oracle-num-sents & \textbf{0.4254} & \textbf{0.2731} & \textbf{0.2184} & \textbf{0.1840} & \textbf{0.8815} & \textbf{0.8870} & \textbf{0.3908} & \textbf{48.1411} \\
extractive-oracle-ratio     & \textbf{0.4303} & \textbf{0.2779} & \textbf{0.2229} & \textbf{0.1872} & \textbf{0.8853} & \textbf{0.8881} & \textbf{0.4109} & \textbf{51.4000} \\
lead-3                      & 0.3576 & 0.1615 & 0.1097 & 0.0871 & 0.8772 & 0.8711 & 0.3419 & \textbf{42.4826} \\
tex-trank                   & 0.3187 & 0.1333 & 0.0861 & 0.0661 & 0.8754 & 0.8640 & 0.3398 & 39.5359 \\
lex-trank                   & 0.3521 & 0.1530 & 0.0975 & 0.0734 & 0.8782 & 0.8710 & 0.3384 & 41.1056 \\
lsa                         & 0.3102 & 0.1256 & 0.0806 & 0.0621 & 0.8733 & 0.8608 & 0.3325 & 39.2861 \\
bert-extractive             & 0.3218 & 0.1228 & 0.0746 & 0.0549 & 0.8711 & 0.8631 & 0.3154 & 37.9083 \\
bart                        & 0.3783 & 0.1818 & 0.1244 & 0.0984 & 0.8753 & 0.8770 & 0.3218 & 41.0940 \\
pegasus                     & 0.3798 & 0.1904 & 0.1305 & \textbf{0.1012} & 0.8788 & 0.8712 & 0.3232 & 40.5537 \\
flan-t5                     & \textbf{0.4187} & \textbf{0.2074} & \textbf{0.1341} & 0.0992 & \textbf{0.8793} & \textbf{0.8884} & \textbf{0.3348} & 40.2826 \\
gpt2                        & 0.1870 & 0.0314 & 0.0063 & 0.0009 & 0.7380 & 0.7424 & 0.1466 & 22.9283 \\
llama3                      & 0.2325 & 0.0500 & 0.0135 & 0.0042 & 0.7876 & 0.7927 & 0.1959 & 27.8445 \\
\bottomrule
\end{tabular}%
}
\end{table}

En este dataset, en el cual no se ha entrenado ningún modelo específicamente, los resultados son un poco diferentes.

De primeras, es cierto que respecto a los métodos extractivos, el rendimiento es similar al del otro dataset. Sin embargo, en este caso, el método extractivo más balanceado sería LexRank, ya que obtiene mejores resultados que TextRank de forma consistente.

Ahora, si nos fijamos en los modelos abstractivos Sequence2Sequence, vemos que Flan-t5 obtiene los mejores resultados en casi todas las métricas. Esto es un cambio importante respecto al otro dataset, ya que Flan-t5 era el modelo con peor rendimiento.

El cambio de rendimiento de Flan-t5 puede ser debido a que este modelo es más generalista y no ha sido entrenado específicamente para el dataset CNN/DailyMail. Por lo tanto, en un dataset no visto, su rendimiento es mejor que el de los modelos más especializados como Bart y Pegasus.

Finalmente, los modelos causales (GPT2 y Llama3) siguen teniendo un rendimiento inferior al de los demás métodos, aunque en este caso, Llama3 obtiene mejores resultados que GPT2 en todas las métricas.




\section{Análisis de Comparativo}

% **TAREA:** Realiza una comparativa de los distintos métodos de *summarization* y compara como varia el rendimiento entre datasets. Como mínimo, debe haber contestación a las siguientes preguntas. El análisis no debe ser un *itemize*.

% 1. ¿Cómo varía cada método en cada uno de los aspectos? ¿Influye la variabilidad de en la abstractividad?
% 2. En términos generarles, ¿Con que método de resumen os quedarías para trabajar con ambos datasets? ¿Variaría dependiendo en que aspecto deseasemos priorizar?

1. ...

Primero que todo, elegiríamos un método abstractivo. Entre ellos, es complicado decidir entre los tres, sin embargo, nos quedaríamos con Pegasus. 

En el primer conjunto de datos, Pegasus y Bart tenían un rendimiento muy bueno por su ventaja de haber sido entrenados específicamente para este dataset. Luego, en este segundo dataset, Flan-t5 ha tenido un rendimiento muy bueno, pero Pegasus no se ha quedado muy atrás. 
Este modelo ha obtenido resultados muy buenos en ambos datasets. A pesar de que no ha sido el mejor en ninguno, ha demostrado ser un modelo robusto y consistente. Parece ser el fácil de adaptar a distintos tipos de documentos y tareas en términos generales.


\section{Impacto de la Abstractividad}

% **TAREA:** En la tabla anterior puedes ver la tabla de correlaciones de "Kendall tau" entre el rendimiento global (media harmónica de todas las métricas) y el nivel de abstractividad de los resúmenes de referencia. Un nivel más bajo de abstractividad (1, por ejemplo) indicaría que el resumen de referencia es muy extractivo, mientras que un nivel más alto (5, por ejemplo) indicaría que el resumen de referencia es muy abstractivo. Teniendo esto presente, realiza un análsis en el que se contesten por lo menos a las siguientes preguntas:

% 1. ¿Existe relación entre el rendimiento y el nivel de abstractividad de los resúmenes de referencia? En caso de haberla, ¿a qué crees que puede estar debido?
% 2. ¿Tiene la misma relación entre rendimiento y nivel de abstractividad dependiendo de si son métodos extractivos o abstractivos? ¿Por qué?


\begin{table}[ht]
\centering
\caption{Correlaciones de Kendall Tau entre el rendimiento global y el nivel de abstractividad}
\label{tab:abstractivity_correlations}
\begin{tabular}{lccc}
\toprule
\textbf{Method} & \textbf{Type} & \textbf{Aspect} & \textbf{Abs-Level Correlation} \\
\midrule
extractive-oracle-num-sents & extractive & performance & -0.625105 \\
extractive-oracle-ratio & extractive & performance & -0.632635 \\
lead-3 & extractive & performance & -0.614855 \\
tex-trank & extractive & performance & -0.528799 \\
lex-trank & extractive & performance & -0.503332 \\
lsa & extractive & performance & -0.476109 \\
bert-extractive & extractive & performance & -0.514631 \\
bart & abstractive & performance & -0.543865 \\
pegasus & abstractive & performance & -0.581181 \\
flan-t5 & abstractive & performance & -0.450436 \\
gpt2 & abstractive & performance & -0.064108 \\
llama3 & abstractive & performance & -0.135576 \\
\bottomrule
\end{tabular}
\end{table}

Teniendo esto presente, realiza un análsis en el que se contesten por lo menos a las siguientes preguntas:

1. Sí, negativo. El origen al que se le puede atribuir es que todas las métricas automáticas se basan en la comparación con los resúmenes de referencia. Por lo tanto, la abstractividad se verá penalizada. Si los resúmenes de referencia son muy extractivos, los métodos extractivos tendrán una ventaja al compararse con ellos, mientras que los métodos abstractivos podrían generar contenido que no esté presente en los resúmenes de referencia, lo que llevaría a una penalización en las métricas.

2. Sí, tienden a tener la misma relación negativa...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
%                                BIBLIOGRAFIA                                 %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\printbibliography

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
%                                 APÉNDICES                                  %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\APPENDIX


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                       EJEMPLOS DE CADA TIPO DE FACTURA                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \chapter{Apéndice correspondencia notebooks}
% \label{appendix:notebooks}
% ...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                              FIN DEL DOCUMENTO                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}

